---
title: "p8105_hw6_cj2493"
author: "Courtney Johnson"
date: "November 20, 2018"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
library(tidyverse)
library(patchwork)
library(modelr)
library(mgcv)
library(purrr)
set.seed(1)
```

## Problem 1

Read in the homicide data:

```{r, read_hom}
homicides = read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") 
```

Clean data accordingly: create city_state variable, a binary variable denoting whether the case was solved, omit cities who don't report victim race or were the product of a data entry mistake, modify victim race to white and non-white, and make sure victim_age is numeric.

```{r, hom_clean}
homicides = homicides %>%
  janitor::clean_names() %>%
  mutate(city_state = str_c(city, ", ", state),
         victim_age = as.numeric(victim_age),
         victim_race = ifelse(victim_race == "White", c("white"), c("non_white")),
         resolved = as.numeric(disposition == "Closed by arrest")) %>%
  filter(city_state != "Dallas, TX" & city_state != "Phoenix, AZ" & city_state != "Kansas City, MO" & city_state != "Tulsa, AL") %>%
  mutate(victim_sex = factor(victim_sex, levels = c("Male", "Female")),
         victim_race = fct_relevel(victim_race, "white"))
```

For Baltimore, MD, use glm function to fit a logistic regression with resolved vs unresolved as outcome and victim age, sex and race as predictors


```{r, baltimore_glm}
baltimore_hom = homicides %>%
  filter(city_state == "Baltimore, MD") 
 

balt_logistic = baltimore_hom %>%
  glm(resolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial()) %>%
  broom::tidy() %>%
  mutate(OR = exp(estimate)) %>%
  filter(term == "victim_racenon_white") %>%
  mutate(OR_ci_low = exp(estimate - 1.96*std.error),
         OR_ci_high = exp(estimate + 1.96*std.error)) %>%
  select(term, estimate, starts_with("OR"))
```

Run glm for each of the cities in the dataset and extract the adjusted OR and CI for solving homicides comparing white and non-white victims.

```{r, pipe_glm}
nest_glm = homicides %>%
  group_by(city_state) %>%
  nest() %>%
  mutate(models = map(data, ~glm(resolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())),
         models = map(models, broom::tidy)) %>%
  select(-data) %>%
  unnest() %>%
  mutate(OR = exp(estimate)) %>%
  filter(term == "victim_racenon_white") %>%
  mutate(OR_ci_low = exp(estimate - 1.96*std.error),
         OR_ci_high = exp(estimate + 1.96*std.error)) %>%
  select(city_state, term, estimate, starts_with("OR"))
```

## Problem 2

Load and clean birthweight data

```{r, read_birth}
birthweight = read_csv("./data/birthweight.csv")
birthweight = birthweight %>%
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace))
birthweight[!complete.cases(birthweight), ] 
```

There are 0 observations, so this shows that there are no missing values in the data set. 


Propose a regression model for birthweight:

```{r, bwt_model}
bwt_model_1 = birthweight %>%
  lm(bwt ~ mrace + fincome + malform + momage + pnumlbw + smoken, data = .) 
```
To come up with my model, I hypothesized what may affect birthweight from prior knowledge. I know that the race of the mother can impact risk for health complications during birth, so I added that to my model. The family income can affect the prenatal care and diet of the mother, so I thought that may have an affect on the health of the baby as well. I know that the older the mother is, the more likely there are to be complications during birth, so I thought that may impact birthweight. I also guessed that number of prior low birth babies would be a good indicator, so I added that to my model. Lastly, I know that mothers who smoke are more likely to have low birthweight babies, so I added that to my model.

```{r, given_models}
lm_length_age = birthweight %>%
  lm(bwt ~ blength + gaweeks, data = .) 

lm_interaction = birthweight %>%
  lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .) 
```

Show a plot of model residuals against fitted values

```{r}
my_mod = birthweight %>%
  modelr::add_predictions(., bwt_model_1) %>%
  modelr::add_residuals(., bwt_model_1) %>%
  ggplot(aes(x = pred, y = resid)) + geom_point() +
  ylim(-2500, 2500) +
  geom_hline(yintercept = 0, color = "blue") +
  labs(x = "Fitted Values",
       y = "Residuals",
       title = "My Model")

mod_length_age = birthweight %>%
  modelr::add_predictions(., lm_length_age) %>%
  modelr::add_residuals(., lm_length_age) %>%
  ggplot(aes(x = pred, y = resid)) + geom_point() +
  ylim(-2500, 2500) +
  geom_hline(yintercept = 0, color = "blue") +
  labs(x = "Fitted Values",
       y = "Residuals",
       title = "Length + Age Model")

interaction_mod = birthweight %>%
  modelr::add_predictions(., lm_interaction) %>%
  modelr::add_residuals(., lm_interaction) %>%
  ggplot(aes(x = pred, y = resid)) + geom_point() +
  ylim(-2500, 2500) +
  geom_hline(yintercept = 0, color = "blue") +
  labs(x = "Fitted Values",
       y = "Residuals",
       title = "Interaction Model")

my_mod + mod_length_age + interaction_mod
```

From these, we can see that the residuals look much better for the given models than the model I tried to make.

Compare the models

```{r, cross_val, warning = FALSE}
cv_df = 
  crossv_mc(birthweight, 100) %>%
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))

cv_df = cv_df %>%
  mutate(bwt_model_1    = map(train, ~lm(bwt ~ mrace + fincome + malform + momage + pnumlbw + smoken, data = .)),
         lm_length_age  = map(train, ~lm(bwt ~ blength + gaweeks, data = .)),
         lm_interaction = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .))) %>%
  mutate(rmse_mod_1       = map2_dbl(bwt_model_1, test, ~rmse(model = .x, data = .y)),
         rmse_length_age  = map2_dbl(lm_length_age, test, ~rmse(model = .x, data = .y)),
         rmse_interaction = map2_dbl(lm_interaction, test, ~rmse(model = .x, data = .y)))

cv_df %>%
  select(starts_with("rmse")) %>%
  gather(key = model, value = rmse) %>%
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>%
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```


From this, we can see that the interaction model has the smalled RMSE for the three models, and is the better of the three.